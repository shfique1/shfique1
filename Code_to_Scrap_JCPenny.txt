from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException
import pandas as pd

# Set up the web driver
driver_path = 'path_to_your_webdriver'  # Replace with the path to your web driver
driver = webdriver.Chrome(driver_path)

# URL of the webpage you want to scrape
url = 'http://example.com'  # Replace with the actual URL
driver.get(url)

# Wait until the first image is clickable
wait = WebDriverWait(driver, 10)
first_image_xpath = 'your_first_image_xpath'  # Replace with the actual XPath of the first image
wait.until(EC.element_to_be_clickable((By.XPATH, first_image_xpath)))

# Extract data for each product
products = []

# Assuming each product is within a common container
product_container_xpath = 'your_product_container_xpath'  # Replace with the actual XPath of the product container
product_elements = driver.find_elements(By.XPATH, product_container_xpath)

for product in product_elements:
    try:
        # Click the product image to load details
        product.find_element(By.XPATH, first_image_xpath).click()
        
        # Extract the details
        name = driver.find_element(By.XPATH, 'your_name_xpath').text  # Replace with actual XPath
        price = driver.find_element(By.XPATH, 'your_price_xpath').text  # Replace with actual XPath
        color = driver.find_element(By.XPATH, 'your_color_xpath').text  # Replace with actual XPath
        description = driver.find_element(By.XPATH, 'your_description_xpath').text  # Replace with actual XPath
        
        # Append the data to the products list
        products.append({
            'Name': name,
            'Price': price,
            'Color': color,
            'Description': description
        })
        
        # Go back to the previous page to continue with the next product
        driver.back()
        wait.until(EC.element_to_be_clickable((By.XPATH, first_image_xpath)))
    
    except NoSuchElementException as e:
        print(f"Error: {e}")
        continue

# Close the driver
driver.quit()

# Create a DataFrame and save it to a CSV file
df = pd.DataFrame(products)
df.to_csv('products.csv', index=False)